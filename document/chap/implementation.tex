\chapter{Implementation}

\section{Decisions}

\subsection{Modularity}

\subsection{Configurability}

\subsection{Security}
\label{security}

Since requests to S3 are usually authenticated through a signature unique to each request there needed to be considerations on if and how these requests can be safely cached without exposing data to unauthorized access.

There were plans to implement bucket policy validations inside the proxy. This would enable failing early in the case that a request was sent with insufficient permission, reducing bandwidth and server load. However, there are some major issues with this idea.
Most significantly, a full permissions check would require access to the credentials of all users. Exposing all credentials to the proxy would pose a significant risk and increase the attack surface. As there is no API access to the credentials defined in the S3 specification, the implementation would also not be universally applicable to all S3-compatible services.
A solution would be to only make the proxy accessible through a set of known credentials against which it could validate the bucket policies. After careful evaluation, this solutions was ultimately judged to be out of scope for this work, as in this case requesters can be assumed to have knowledge of the proxy and therefore can be expected to have the correct credentials, in which case there would be limited room for acceleration.

The solution that was eventually adopted is that the proxy can optionally be configured to validate incoming requests against a provided set of credentials (A), but will replace the signature with one calculated from its own credentials (B) before forwarding the request.
Although acceptable within the scope of this work, this approach does come with some issues and poses some limitations that should be considered. 
\begin{enumerate}
	\item If A is configured and B has permissions that A does not have, A can bypass this lack of permissions. Conversely, if A has permissions that B does not have, downstream requests may fail unexpectedly. This can be mitigated by using the same set of credentials for A and B.
	\item If A is configured, a requests signature must match A even if the bucket policy would allow for public access.
	\item If no credentials are configured for A, all requests to the proxy will be executed with B without any validation of signatures on the incoming request. Exposing the proxy in this state poses significant risk of unintended unauthorized access.
\end{enumerate}

\section{Components}

This section focuses on the specific implementations for the components described in \ref{architecture} that were created for the stated goal of creating a proxy for the S3 protocol with additional cache functionality.

\subsection{S3 Server}

The Server is the component responsible for accepting requests made to the proxy. It is initialized by providing a ServerBuilder with a Handler to which it will forward all accepted requests.

The S3Server is built upon a traditional HTTP server provided by hyper

\subsection{Middleware}

\subsubsection{Caching}
\begin{enumerate}
	\item Cache policy: TinyLFU
	\item Size aware eviction
	\item Headers not counted towards size
	\item global Time-To-Live and Time-To-Idle + configurable per operation
\end{enumerate}

\subsection{S3 Client}

\subsection{Pipeline}

The Pipeline is a management structure composed of a ServerBuilder, any number of Middlewares and a Client. It is responsible for assembling the different components passed to it into a cohesive unit. When initialized with all required components it first constructs the RequestProcessor from the client and middlewares together with a broadcast channel that is registered with all components. The broadcast channel is used to pass events other than requests, like the ones produced by the Webhook component. It then converts the RequestProcessor into a Handler, which is then used to finalize the ServerBuilder to start the Server.

\subsection{Webhook}

\section{Challenges}

\subsection{smithy}
\subsection{s3s}